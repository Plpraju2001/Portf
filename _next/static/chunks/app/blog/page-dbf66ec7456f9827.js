(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[831],{3441:(e,n,t)=>{Promise.resolve().then(t.bind(t,8700))},8700:(e,n,t)=>{"use strict";t.r(n),t.d(n,{default:()=>c});var i=t(5155),a=t(273),s=t(2619),r=t.n(s);let o=[{id:1,title:"Starting My Data Science Bootcamp",excerpt:"I've just started a bootcamp to strengthen my foundational skills in data science, machine learning, and deep learning.",date:"October 29, 2025",readTime:"2 min read",category:"Learning Journey",content:"\n      <h2>Just Getting Started</h2>\n      <p>I've recently started a data science bootcamp to strengthen my foundational skills. This is a journey to deepen my understanding of core concepts in data science, machine learning, and deep learning.</p>\n      \n      <h2>What I'm Learning</h2>\n      <p>The bootcamp covers three main areas:</p>\n      <ul>\n        <li><strong>Data Science:</strong> Statistics, probability, exploratory data analysis, and data preprocessing</li>\n        <li><strong>Machine Learning:</strong> Supervised and unsupervised learning, model evaluation, and feature engineering</li>\n        <li><strong>Deep Learning:</strong> Neural networks, CNNs, RNNs, and modern architectures</li>\n      </ul>\n      \n      <h2>Why This Matters</h2>\n      <p>With 3+ years of practical experience, I want to ensure I have solid fundamentals to build upon. The field moves fast, and having strong foundational knowledge will help me adapt to new technologies and techniques more effectively.</p>\n      \n      <p>I'll be documenting my journey as I go. Stay tuned for updates!</p>\n    "},{id:2,title:"Completed Data Science Basics",excerpt:"I've finished the basics of data science, machine learning, and deep learning. The field is booming with opportunities.",date:"October 30, 2025",readTime:"3 min read",category:"Career Insights",content:"\n      <h2>Basics Complete</h2>\n      <p>I've completed the fundamentals of data science, machine learning, and deep learning. This has reinforced my existing experience and added depth to my understanding of the field.</p>\n      \n      <h2>What I Learned</h2>\n      <ul>\n        <li><strong>Data Science:</strong> Statistics, probability, EDA, and data preprocessing</li>\n        <li><strong>Machine Learning:</strong> Core algorithms, model evaluation, and feature engineering</li>\n        <li><strong>Deep Learning:</strong> Neural networks, CNNs, RNNs, and modern architectures</li>\n      </ul>\n      \n      <h2>The Market Boom</h2>\n      <p>The data science field is experiencing unprecedented growth. Here's what I'm seeing:</p>\n      \n      <h3>Unprecedented Demand</h3>\n      <ul>\n        <li>Record job postings across all industries</li>\n        <li>Generous compensation packages</li>\n        <li>Expanded remote opportunities</li>\n      </ul>\n      \n      <h3>Why It's Booming</h3>\n      <ul>\n        <li><strong>AI Revolution:</strong> Generative AI and LLMs have made data science mission-critical</li>\n        <li><strong>Data Explosion:</strong> Companies need skilled professionals to harness data</li>\n        <li><strong>Competitive Pressure:</strong> Data-driven decisions are key to success</li>\n      </ul>\n      \n      <h2>Hot Areas</h2>\n      <ul>\n        <li>Generative AI & LLMs</li>\n        <li>MLOps and production deployment</li>\n        <li>Causal inference and advanced analytics</li>\n        <li>Customer analytics and personalization</li>\n      </ul>\n      \n      <h2>Looking Forward</h2>\n      <p>With solid fundamentals and practical experience, I'm excited about the opportunities ahead. The field is evolving rapidly, and there's never been a better time to be a data scientist.</p>\n      \n      <p>I'm looking forward to diving deeper into advanced topics and sharing more insights as I continue learning!</p>\n    "},{id:3,title:"Advanced Causal Inference: Beyond Traditional A/B Testing",excerpt:"Deep dive into sophisticated causal inference methods I'm exploring to solve complex business problems. Sharing insights from my latest research on uplift modeling and heterogeneous treatment effects.",date:"October 25, 2025",readTime:"12 min read",category:"Advanced Analytics",content:"\n      <h2>Introduction to Advanced Causal Inference</h2>\n      <p>As an experienced Data Scientist, I've been diving deeper into sophisticated causal inference methods that go far beyond traditional A/B testing. In this post, I'll share insights from my latest research and practical applications of advanced causal modeling techniques.</p>\n      \n      <h2>Beyond Traditional A/B Testing</h2>\n      <p>While A/B testing remains valuable, modern businesses face complex scenarios where traditional methods fall short:</p>\n      <ul>\n        <li><strong>Network Effects:</strong> When user behaviors influence each other</li>\n        <li><strong>Heterogeneous Treatment Effects:</strong> Different responses across user segments</li>\n        <li><strong>Time-varying Effects:</strong> Treatment impacts that change over time</li>\n        <li><strong>Selection Bias:</strong> Non-random assignment in observational data</li>\n      </ul>\n      \n      <h2>Advanced Methods I'm Exploring</h2>\n      <p>Here are the sophisticated techniques I've been implementing and teaching:</p>\n      <ul>\n        <li><strong>Uplift Modeling:</strong> Identifying individuals most likely to respond to treatment</li>\n        <li><strong>Instrumental Variables:</strong> Using natural experiments to establish causality</li>\n        <li><strong>Regression Discontinuity:</strong> Exploiting arbitrary thresholds for causal identification</li>\n        <li><strong>Difference-in-Differences:</strong> Comparing treatment and control groups over time</li>\n      </ul>\n      \n      <h2>Practical Applications</h2>\n      <p>In my current role, I've applied these methods to solve complex business problems:</p>\n      <ul>\n        <li>Marketing campaign optimization with heterogeneous customer responses</li>\n        <li>Product feature impact analysis accounting for user network effects</li>\n        <li>Pricing strategy evaluation using natural experiments</li>\n        <li>Customer retention modeling with time-varying treatment effects</li>\n      </ul>\n      \n      <h2>Teaching and Knowledge Sharing</h2>\n      <p>One of my passions is sharing these advanced concepts with the data science community. Through this blog and my work, I aim to:</p>\n      <ul>\n        <li>Demystify complex causal inference concepts</li>\n        <li>Provide practical implementation guidance</li>\n        <li>Share real-world case studies and lessons learned</li>\n        <li>Help fellow data scientists avoid common pitfalls</li>\n      </ul>\n      \n      <h2>What's Next</h2>\n      <p>I'm currently exploring Bayesian causal inference methods and their applications in high-stakes decision making. Stay tuned for more deep dives into advanced statistical methods, practical implementations, and insights from cutting-edge research!</p>\n    "},{id:4,title:"Data Science Tips & Tricks: Pro Techniques from the Field",excerpt:"Essential tips and tricks I've learned from years of data science practice. From debugging models to optimizing performance, these insights will save you hours and improve your results.",date:"October 28, 2025",readTime:"8 min read",category:"Tips & Tricks",content:"\n      <h2>Introduction</h2>\n      <p>After years of working in data science, I've accumulated numerous tips and tricks that have saved me countless hours and improved my results significantly. In this post, I'll share the most valuable techniques I use daily.</p>\n      \n      <h2>Data Preprocessing Tricks</h2>\n      <h3>1. Smart Missing Value Handling</h3>\n      <p><strong>Pro Tip:</strong> Instead of just dropping missing values, create a \"missing indicator\" feature. This often contains valuable information about data quality and user behavior patterns.</p>\n      <pre><code># Create missing indicators\ndf['has_missing_income'] = df['income'].isnull().astype(int)\ndf['income_filled'] = df['income'].fillna(df['income'].median())</code></pre>\n      \n      <h3>2. Feature Engineering Shortcuts</h3>\n      <p><strong>Pro Tip:</strong> Use pandas' built-in datetime features more effectively:</p>\n      <pre><code># Extract multiple time features in one go\ndf['year'] = df['date'].dt.year\ndf['month'] = df['date'].dt.month\ndf['day_of_week'] = df['date'].dt.dayofweek\ndf['is_weekend'] = df['date'].dt.dayofweek.isin([5, 6])</code></pre>\n      \n      <h2>Model Development Hacks</h2>\n      <h3>3. Quick Model Comparison</h3>\n      <p><strong>Pro Tip:</strong> Use sklearn's VotingClassifier for rapid model comparison:</p>\n      <pre><code>from sklearn.ensemble import VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\n# Quick ensemble comparison\nmodels = [\n    ('lr', LogisticRegression()),\n    ('rf', RandomForestClassifier()),\n    ('svm', SVC(probability=True))\n]\nensemble = VotingClassifier(models, voting='soft')</code></pre>\n      \n      <h3>4. Hyperparameter Tuning Shortcut</h3>\n      <p><strong>Pro Tip:</strong> Start with a coarse grid search, then zoom in on promising regions:</p>\n      <pre><code># Coarse search first\nparam_grid = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [5, 10, 20, None],\n    'min_samples_split': [2, 5, 10]\n}\n\n# Then fine-tune around best parameters\nparam_grid_fine = {\n    'n_estimators': [80, 100, 120],\n    'max_depth': [8, 10, 12],\n    'min_samples_split': [3, 5, 7]\n}</code></pre>\n      \n      <h2>Performance Optimization</h2>\n      <h3>5. Memory Optimization</h3>\n      <p><strong>Pro Tip:</strong> Reduce memory usage by optimizing data types:</p>\n      <pre><code># Convert to appropriate dtypes\ndf['category_col'] = df['category_col'].astype('category')\ndf['int_col'] = pd.to_numeric(df['int_col'], downcast='integer')\ndf['float_col'] = pd.to_numeric(df['float_col'], downcast='float')</code></pre>\n      \n      <h3>6. Parallel Processing</h3>\n      <p><strong>Pro Tip:</strong> Use joblib for easy parallelization:</p>\n      <pre><code>from joblib import Parallel, delayed\n\n# Parallel feature engineering\ndef process_feature(data):\n    return data.apply(some_function)\n\nresults = Parallel(n_jobs=-1)(\n    delayed(process_feature)(df[col]) for col in feature_columns\n)</code></pre>\n      \n      <h2>Debugging & Validation</h2>\n      <h3>7. Model Debugging Checklist</h3>\n      <p><strong>Pro Tip:</strong> When models perform poorly, check these in order:</p>\n      <ul>\n        <li>Data leakage (future information in training data)</li>\n        <li>Target variable distribution (class imbalance)</li>\n        <li>Feature scaling and normalization</li>\n        <li>Cross-validation setup (temporal vs. random splits)</li>\n        <li>Hyperparameter ranges (too narrow/wide)</li>\n      </ul>\n      \n      <h3>8. Quick Validation Setup</h3>\n      <p><strong>Pro Tip:</strong> Use sklearn's cross_val_score with custom scoring:</p>\n      <pre><code>from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import make_scorer\n\n# Custom scoring function\ndef custom_metric(y_true, y_pred):\n    return your_custom_calculation(y_true, y_pred)\n\ncustom_scorer = make_scorer(custom_metric, greater_is_better=True)\nscores = cross_val_score(model, X, y, cv=5, scoring=custom_scorer)</code></pre>\n      \n      <h2>Visualization Hacks</h2>\n      <h3>9. Quick EDA Template</h3>\n      <p><strong>Pro Tip:</strong> Create reusable EDA functions:</p>\n      <pre><code>def quick_eda(df, target_col=None):\n    print(f\"Shape: {df.shape}\")\n    print(f\"Missing values: {df.isnull().sum().sum()}\")\n    \n    if target_col:\n        print(f\"Target distribution: {df[target_col].value_counts()}\")\n    \n    # Correlation heatmap\n    plt.figure(figsize=(12, 8))\n    sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n    plt.show()</code></pre>\n      \n      <h3>10. Model Interpretation Shortcuts</h3>\n      <p><strong>Pro Tip:</strong> Use SHAP for quick model interpretation:</p>\n      <pre><code>import shap\n\n# Quick SHAP analysis\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(X_test)\nshap.summary_plot(shap_values, X_test)</code></pre>\n      \n      <h2>Production Deployment Tips</h2>\n      <h3>11. Model Versioning</h3>\n      <p><strong>Pro Tip:</strong> Always version your models and track performance:</p>\n      <pre><code>import joblib\nimport datetime\n\n# Save with timestamp\ntimestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nmodel_name = f\"model_v{timestamp}.joblib\"\njoblib.dump(model, model_name)</code></pre>\n      \n      <h3>12. Monitoring Setup</h3>\n      <p><strong>Pro Tip:</strong> Set up basic model monitoring from day one:</p>\n      <ul>\n        <li>Track prediction distributions over time</li>\n        <li>Monitor feature drift</li>\n        <li>Set up alerts for performance degradation</li>\n        <li>Log prediction confidence scores</li>\n      </ul>\n      \n      <h2>Final Thoughts</h2>\n      <p>These tips have been game-changers in my data science practice. The key is to build these techniques into your workflow gradually. Start with the ones that address your current pain points, and you'll see immediate improvements in efficiency and results.</p>\n      \n      <p>What tips and tricks have you discovered? I'd love to hear about your favorite techniques in the comments!</p>\n    "}],l=e=>{let{post:n}=e;return(0,i.jsx)(a.P.article,{className:"bg-white rounded-lg shadow-lg overflow-hidden mb-8",initial:{opacity:0,y:30},animate:{opacity:1,y:0},transition:{duration:.6},whileHover:{y:-5},children:(0,i.jsxs)("div",{className:"p-8",children:[(0,i.jsxs)("div",{className:"flex flex-wrap gap-2 mb-4",children:[(0,i.jsx)("span",{className:"bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm font-medium",children:n.category}),(0,i.jsx)("span",{className:"bg-gray-100 text-gray-600 px-3 py-1 rounded-full text-sm",children:n.readTime})]}),(0,i.jsx)("h1",{className:"text-3xl font-bold text-gray-800 mb-4",children:n.title}),(0,i.jsxs)("div",{className:"flex items-center text-gray-500 mb-6",children:[(0,i.jsx)("svg",{className:"w-4 h-4 mr-2",fill:"none",stroke:"currentColor",viewBox:"0 0 24 24",children:(0,i.jsx)("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"})}),n.date]}),(0,i.jsx)("p",{className:"text-lg text-gray-600 mb-6 leading-relaxed",children:n.excerpt}),(0,i.jsx)("div",{className:"prose prose-lg max-w-none",dangerouslySetInnerHTML:{__html:n.content}})]})})};function c(){return(0,i.jsxs)("div",{className:"min-h-screen bg-gray-50",children:[(0,i.jsx)(a.P.header,{className:"bg-white shadow-sm",initial:{opacity:0,y:-20},animate:{opacity:1,y:0},transition:{duration:.6},children:(0,i.jsx)("div",{className:"container mx-auto px-6 py-4",children:(0,i.jsxs)("div",{className:"flex justify-between items-center",children:[(0,i.jsx)(r(),{href:"/",className:"text-2xl font-bold text-gray-800 hover:text-blue-600 transition-colors",children:"Lakshmipathiraju"}),(0,i.jsxs)("nav",{className:"hidden md:flex space-x-8",children:[(0,i.jsx)(r(),{href:"/",className:"text-gray-700 hover:text-blue-600 transition-colors",children:"Home"}),(0,i.jsx)(r(),{href:"/#about",className:"text-gray-700 hover:text-blue-600 transition-colors",children:"About"}),(0,i.jsx)(r(),{href:"/#projects",className:"text-gray-700 hover:text-blue-600 transition-colors",children:"Projects"}),(0,i.jsx)(r(),{href:"/#experience",className:"text-gray-700 hover:text-blue-600 transition-colors",children:"Experience"}),(0,i.jsx)(r(),{href:"/blog",className:"text-blue-600 font-semibold",children:"Blog"}),(0,i.jsx)(r(),{href:"/#contact",className:"text-gray-700 hover:text-blue-600 transition-colors",children:"Contact"})]})]})})}),(0,i.jsx)("section",{className:"py-20 bg-gradient-to-r from-blue-600 to-purple-600 text-white",children:(0,i.jsx)("div",{className:"container mx-auto px-6 text-center",children:(0,i.jsxs)(a.P.div,{initial:{opacity:0,y:30},animate:{opacity:1,y:0},transition:{duration:.8},children:[(0,i.jsx)("h1",{className:"text-5xl md:text-6xl font-bold mb-6",children:"Data Science Deep Dives"}),(0,i.jsx)("p",{className:"text-xl md:text-2xl mb-8 opacity-90",children:"Advanced Analytics, Research Insights, and Teaching Moments"}),(0,i.jsx)("p",{className:"text-lg opacity-80 max-w-3xl mx-auto",children:"Sharing advanced data science techniques, research findings, and practical applications. From sophisticated causal inference to cutting-edge ML methods - learn with an experienced practitioner."})]})})}),(0,i.jsx)("section",{className:"py-20",children:(0,i.jsx)("div",{className:"container mx-auto px-6",children:(0,i.jsxs)(a.P.div,{initial:{opacity:0,y:30},animate:{opacity:1,y:0},transition:{duration:.8},className:"max-w-4xl mx-auto",children:[(0,i.jsx)("h2",{className:"text-3xl font-bold text-gray-800 mb-12 text-center",children:"Latest Posts"}),o.map(e=>(0,i.jsx)(l,{post:e},e.id))]})})}),(0,i.jsx)("footer",{className:"bg-gray-800 text-white py-8",children:(0,i.jsxs)("div",{className:"container mx-auto px-6 text-center",children:[(0,i.jsxs)("div",{className:"flex justify-center space-x-6 mb-4",children:[(0,i.jsx)("a",{href:"https://github.com/plpraju2001",target:"_blank",rel:"noopener noreferrer",className:"text-gray-400 hover:text-white transition-colors",children:(0,i.jsx)("svg",{className:"w-6 h-6",fill:"currentColor",viewBox:"0 0 24 24",children:(0,i.jsx)("path",{d:"M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"})})}),(0,i.jsx)("a",{href:"https://www.linkedin.com/in/lakshmipathirajup",target:"_blank",rel:"noopener noreferrer",className:"text-gray-400 hover:text-white transition-colors",children:(0,i.jsx)("svg",{className:"w-6 h-6",fill:"currentColor",viewBox:"0 0 24 24",children:(0,i.jsx)("path",{d:"M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"})})})]}),(0,i.jsx)("p",{className:"text-gray-400",children:"\xa9 2024 Lakshmipathiraju Pericharla. All rights reserved."})]})})]})}}},e=>{e.O(0,[847,619,441,255,358],()=>e(e.s=3441)),_N_E=e.O()}]);